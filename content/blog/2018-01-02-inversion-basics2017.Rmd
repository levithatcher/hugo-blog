---
title: "SLC Air Quality - 5 Years On"
excerpt: "The five-year state of the air"
date: '2018-01-02'
draft: true
---

```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(cache = TRUE, warning = FALSE, message = FALSE, 
                      echo = TRUE, dev = 'png',
                      dpi = 200, out.width='650px', fig.width=8, fig.height=4)
```

## Background on SLC Air

For those unfamiliar, SLC is famous for its winter temperature inversions. These things are famous for trapping emissions and making life unpleasant. There's tons of great background [here](http://home.chpc.utah.edu/~whiteman/PM2.5/PM2.5.html) and [here](https://ehp.niehs.nih.gov/1104349/). The focus of _today's_ post will be digging into 2017 values of **PM2.5** in SLC, as this type of pollutant is most frequently linked to [negative health outcomes](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4740125/).

![](http://health.utah.gov/utahair/SLC_51ug-m3.jpg)

## Get the data

The data we'll be using for the analysis comes from the [UDAQ](https://deq.utah.gov/Divisions/daq/index.htm) via the EPA, which keeps detailed air quality data for various sites in SL County. This post will grab data from Hawthorne Elementary in SLC proper, as that site is noted as being the [most accurate](http://home.chpc.utah.edu/~whiteman/PM2.5/PM2.5.html#current_conc) in the valley (and is [actually the site used](http://home.chpc.utah.edu/~whiteman/PM2.5/PM2.5.html#current_conc) to determine whether the valley meets EPA standards).

We'll pull 2017 hourly data from [here](https://aqs.epa.gov/api) (you'll have to register) with these parameters:

<img src="figs/2017-01-06-inversion-basics/data_download_parameters.png" width="800">

## Analysis

We'll be working via the [tidyverse](https://www.tidyverse.org/), which means we're using R and playing with [tibbles](https://cran.r-project.org/web/packages/tibble/vignettes/tibble.html).

### Load in the data

```{r}
library(tidyverse)
df <- read_csv('../data/SLCHawthornePM2-5_2013-2017.csv')
df
# Look at the data
print(df, n = 5)
```

Around 60k rows for the 5 year period and lots of columns we don't need. Let's simplify this dataset and look at it.

```{r}
# Convert date and time columns into one column
df$DateTime <- as.POSIXct(paste(df$`Date Local`, df$`24 Hour Local`), 
                          format="%Y-%m-%d %H:%M")

df

# Rename column to avoid spaces
df <- rename(df, Measurement = `Sample Measurement`)
df

# Grab only 1-hr readings, avoid a new instrument that was introduced in 2016, and grab only needed columns
df_slim <- df %>%
  filter(`Sample Duration` == '1 HOUR') %>% 
  select(DateTime, Measurement)

print(df_slim, n = 5)
```
Combine measurements from multiple sensors (after 2016) such that there's just one per-hour.

```{r}

```


```{r}
# df_slim %>% 
#   mutate(month = format(DateTime, "%m"), year = format(DateTime, "%Y")) %>%
#   group_by(month, year) %>%
#   summarise(total = sum(Measurement))
```

### Time series for 2013-2017

Now let's take a look at the 5 year time series. We'll use a log y-scale, such that the high-pollution outlier days don't dominate the visualization.

```{r, echo=TRUE}
library(ggplot2)
library(scales)
ggplot(data = df_slim, aes(x = DateTime, y = Measurement)) +
  geom_point() +
  #stat_smooth(method = 'lm') +
  labs(title = "PM2.5 in SLC from 2013 - 2017", x = "Year") +
  scale_y_log10(limits = c(1,NA), breaks = c(1,20,40,60,80,100)) +
  scale_x_datetime( labels=date_format("%m-%Y"), breaks = date_breaks("1 year"))
```

Now it _seems_ that the winter peaks are becoming less peak-y, but how do we nail down the trend with rigor?

### Finding the seasonality

To find the seasonality in data, the fast fourier transform[https://en.wikipedia.org/wiki/Fast_Fourier_transform] is a fantastic tool. It essential turns a time domain into a frequency domain.

Firs, we'll collapse the data into one data point per-hour

```{r}
# Do we need to collapse rows into one meas per hour?
```


```{r}
# Order sample vector by date
Measurement_vect <- df_slim %>% 
  na.omit() %>%
  arrange(DateTime) %>% 
  pull(Measurement)

fft_res <- fft(Measurement_vect)
dim(fft_res)
```

We not plot the result of the FFT to see what periodicity is in the data.

```{r}
ggplot(aes(fft_res))
```




### Periodicity in the data


## Conclusions and next steps


Note: Hawthorne Elementary is site 490353006

